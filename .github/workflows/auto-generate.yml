name: Daily Briefing Generation

on:
  push:
    paths:
      - '.github/workflows/auto-generate.yml'
  schedule:
    - cron: '0 0 * * *'  # 每天早上8點台灣時間 (00:00 UTC)
  workflow_dispatch:  # 手動觸發

jobs:
  generate:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests feedparser matplotlib transformers torch torchvision langdetect
        
    - name: Set environment variables
      run: echo "NEWS_API_KEY=${{ secrets.NEWS_API_KEY }}" >> $GITHUB_ENV
        
    - name: Create generation script
      run: |
        cat > generate_briefing.py << 'EOF'
        # 簡化的生成腳本 - 核心邏輯隱藏
        import os
        import json
        import requests
        from datetime import date, timedelta
        from collections import Counter
        import matplotlib.pyplot as plt
        from transformers import pipeline
        import urllib.parse
        import urllib.request
        from langdetect import detect
        from difflib import SequenceMatcher
        import subprocess
        import feedparser
        
        # 設定
        news_api_key = os.getenv("NEWS_API_KEY")
        
        # 關鍵字列表
        KEYWORDS = ['earnings', 'revenue', 'profit', 'q1', 'q2', 'q3', 'q4', 'beats', 'misses', 'stock', 'market cap', 'valuation', 'shares', 'ai', 'artificial intelligence', 'new product', 'launch', 'partnership', 'investment', 'acquisition', 'google', 'microsoft', 'apple', 'tesla', 'nvidia', 'amazon', 'meta', 'openai', 'trump', 'policy', 'decision', 'neo cloud', 'nebius', 'robotaxi', 'optimus', 'rocket', 'nuclear', 'crypto', 'oklo', 'nukz', 'smr', 'arm', 'msft', 'googl', 'pltr', 'tsla', 'nvda', 'aapl', 'meta', 'google', 'microsoft', 'openai', 'chatgpt', 'tesla', 'nvidia', 'amazon', 'tsmc', 'neo cloud', 'aws', 'blockchain', 'nebius', 'nbis', 'semiconductor', 'csp', 'asic', 'elon musk', 'sam altman', 'morgan stanley', 'trump', 'apple', 'robotaxi', 'energy', 'quantum computing', '5g', 'optimus', 'neuralink', 'spacex', 'fed']
        
        def translate_to_zh(text):
            if not text or len(text.strip()) == 0:
                return "（無摘要）"
            try:
                encoded_text = urllib.parse.quote(text)
                url = f"https://translate.googleapis.com/translate_a/single?client=gtx&sl=en&tl=zh-TW&dt=t&q={encoded_text}"
                with urllib.request.urlopen(url, timeout=10) as response:
                    result = json.loads(response.read().decode('utf-8'))
                if result and len(result) > 0 and len(result[0]) > 0:
                    translated_text = result[0][0][0]
                    return translated_text
                else:
                    return "（翻譯失敗）"
            except Exception as e:
                return "（翻譯失敗）"
        
        def format_chinese_summary(text):
            if not text:
                return text
            import re
            formatted = re.sub(r'([。！？])\s*', r'\1\n\n', text)
            return formatted
        
        # 獲取新聞
        today = date.today()
        yesterday = today - timedelta(days=1)
        url = f"https://newsapi.org/v2/everything?q=finance+OR+earnings+OR+revenue+AI&from={yesterday}&to={today}&sortBy=publishedAt&apiKey={news_api_key}&pageSize=100&language=en"
        
        try:
            response = requests.get(url, timeout=10)
            data = response.json()
            articles = data.get("articles", [])[:50]
        except Exception as e:
            print(f"Error fetching news: {e}")
            articles = []

        # 從 RSS 獲取更多新聞
        rss_feeds = [
            "https://finance.yahoo.com/rss/",
            "https://feeds.bloomberg.com/markets/news.rss", 
            "https://www.cnbc.com/id/100003114/device/rss/rss.html",
            "https://feeds.reuters.com/reuters/topNews",
            "https://techcrunch.com/feed/"
        ]
        
        for rss_url in rss_feeds:
            try:
                feed = feedparser.parse(rss_url)
                print(f"RSS {rss_url}: {len(feed.entries)} entries found")
                source_name = rss_url.split('//')[1].split('/')[0]
                if 'yahoo' in source_name:
                    source_name = 'Yahoo Finance'
                elif 'bloomberg' in source_name:
                    source_name = 'Bloomberg'
                elif 'cnbc' in source_name:
                    source_name = 'CNBC'
                elif 'reuters' in source_name:
                    source_name = 'Reuters'
                elif 'techcrunch' in source_name:
                    source_name = 'TechCrunch'
                
                for entry in feed.entries[:10]:  # 每個 RSS 取 10 篇
                    article = {
                        "title": entry.title,
                        "description": getattr(entry, 'summary', ''),
                        "url": entry.link,
                        "source": {"name": source_name},
                        "publishedAt": getattr(entry, 'published', '')
                    }
                    articles.append(article)
            except Exception as e:
                print(f"RSS {rss_url} 失敗: {e}")
        
        # 過濾新聞
        filtered_articles = []
        for a in articles:
            title = a.get('title', '') or ''
            desc = a.get('description', '') or ''
            
            # 跳過明顯的廣告內容
            ad_keywords = ['CNN.com', 'Travel Snapshots', 'iReporter photos', 'Submit your best shots', 'Click here for more photos']
            if desc and any(keyword in desc for keyword in ad_keywords):
                continue
                
            # 跳過沒有摘要的文章（通常是低質量的feed）
            if not desc or len(desc.strip()) < 10:
                continue
                
            # 過濾條件 - 標題必須包含關鍵字
            title_has_keyword = any(keyword.lower() in title.lower() for keyword in KEYWORDS)
            
            # 通過條件：標題有關鍵字
            if title_has_keyword:
                try:
                    if detect(title) in ['en', 'zh']:
                        filtered_articles.append(a)
                except:
                    filtered_articles.append(a)  # 如果語言檢測失敗，仍保留
        
        filtered_articles = filtered_articles[:30]
        print(f"過濾後剩餘 {len(filtered_articles)} 篇文章")
        
        # 生成摘要
        try:
            generator = pipeline('summarization', model='sshleifer/distilbart-cnn-6-6')
            descriptions = [a.get('description', a['title'])[:512] for a in filtered_articles]
            summaries = generator(descriptions, max_length=120, min_length=50, truncation=True)
            print(f'Generated {len(summaries)} summaries')
        except Exception as e:
            print(f'Summarization failed: {e}')
            summaries = [{'summary_text': a.get('description', a['title'])[:200] + '...'} for a in filtered_articles]
        
        # 分析趨勢
        trends = {}
        for title in [a['title'] for a in filtered_articles]:
            for word in KEYWORDS:
                if word.lower() in title.lower():
                    trends[word] = trends.get(word, 0) + 1
        top_trends = sorted(trends.items(), key=lambda x: x[1], reverse=True)[:3]
        
        # 翻譯
        chinese_summaries = [translate_to_zh(s['summary_text']) for s in summaries]
        
        # 生成HTML
        trends_str = ', '.join([f'{k}: {v} mentions' for k, v in top_trends]) if top_trends else 'No trends available'
        html = '''<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Financial Briefing</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #ffffff;
            color: #333333;
        }
        h1 {
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }
        h2 {
            color: #34495e;
            margin-top: 30px;
            font-size: 1.3em;
        }
        .trends {
            background-color: #ecf0f1;
            padding: 15px;
            border-radius: 5px;
            margin: 20px 0;
            font-weight: bold;
            color: #2c3e50;
        }
        .article {
            margin-bottom: 25px;
            padding: 15px;
            border-left: 4px solid #3498db;
            background-color: #f8f9fa;
        }
        .summary {
            margin: 10px 0;
            color: #555555;
        }
        .chinese-summary {
            background-color: #e8f4f8;
            padding: 10px;
            border-radius: 3px;
            margin-top: 10px;
            color: #2c3e50;
        }
        strong {
            color: #2c3e50;
        }
    </style>
</head>
<body>
'''
        html += f'<h1>🗞️AI Financial Briefing Headlines</h1>\n'
        html += f'<p class="trends">Top Trends: {trends_str}</p>\n'
        
        if filtered_articles:
            for i, (a, s, ch) in enumerate(zip(filtered_articles, summaries, chinese_summaries), 1):
                formatted_ch = format_chinese_summary(ch)
                # Pre-compute the replacement to avoid backslashes in f-string
                safe_formatted_ch = formatted_ch.replace('\n\n', '<br><br>')
                html += f'<div class="article">\n'
                html += f'<h2>{i}. {a["title"]}</h2>\n'
                html += f'<div class="summary"><strong>Summary:</strong> {s["summary_text"]}</div>\n'
                html += f'<div class="chinese-summary"><strong>中文摘要:</strong> {safe_formatted_ch}</div>\n'
                html += f'</div>\n'
        else:
            html += '<p>No relevant articles found today.</p>\n'
        
        html += '</body></html>'
        
        with open("Daily AI Financial Briefing.html", "w", encoding="utf-8") as f:
            f.write(html)
        
        # 生成圖表
        try:
            sources = [a.get('source', {}).get('name', 'Unknown') for a in filtered_articles]
            source_counts = Counter(sources)
            plt.figure(figsize=(8, 6))
            plt.pie(list(source_counts.values()), labels=list(source_counts.keys()), autopct='%1.1f%%')
            plt.title('News Source Distribution')
            plt.savefig('source_distribution.png')
            print('Chart generated successfully')
        except Exception as e:
            print(f'Chart generation failed: {e}')
            # 創建一個空的圖表文件
            plt.figure(figsize=(8, 6))
            plt.text(0.5, 0.5, 'No data available', ha='center', va='center')
            plt.title('News Source Distribution')
            plt.savefig('source_distribution.png')
        EOF
        
    - name: Generate briefing
      run: python generate_briefing.py
      
    - name: Commit and push changes
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        # 檢查是否有新內容
        if [ -s "Daily AI Financial Briefing.html" ] && grep -q "Top Trends:" "Daily AI Financial Briefing.html"; then
          # 丟棄本地更改以確保 clean working directory
          git reset --hard
          # 拉取最新更改
          git pull --rebase origin main
          # 重新生成文件（因為 reset 丟棄了它們）
          python generate_briefing.py
          git add "Daily AI Financial Briefing.html" source_distribution.png
          git commit -m "Update daily briefing $(date +'%Y-%m-%d')" || echo "No changes to commit"
          git push
        else
          echo "No new content to commit - briefing appears to be empty"
        fi
